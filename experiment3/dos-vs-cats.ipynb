import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import numpy as np

import warnings
warnings.filterwarnings('ignore')

from tensorflow import keras
from keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.utils import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.preprocessing import image_dataset_from_directory

import os
import matplotlib.image as mpimg 
import kagglehub

""" # Download the latest version of the dataset from Kaggle """
path = kagglehub.dataset_download("anthonytherrien/dog-vs-cat")

print("Path to dataset files:", path)

""" # List the files in the dataset directory to confirm files have been downloaded """
print("Files in dataset directory:", os.listdir(path))

""" # Define the path to the 'animals' directory """
animals_path = os.path.join(path, "animals")

""" # List files inside the 'animals' directory to ensure correct dataset structure """
print("Files in 'animals' directory:", os.listdir(animals_path))

""" # Define the base directory for 'dog-vs-cat-classification' """
base_dir = os.path.join(path, "animals")

""" # Define paths for 'cat' and 'dog' directories """
cat_dir = os.path.join(base_dir, "cat")
dog_dir = os.path.join(base_dir, "dog")

""" # List filenames in 'cat' and 'dog' directories for inspection """
cat_names = os.listdir(cat_dir)
dog_names = os.listdir(dog_dir)

""" # Set up the figure for displaying images in a grid """
fig = plt.gcf()
fig.set_size_inches(16, 16)

""" # Define the index for selecting images """
pic_index = 210

""" # Get a list of image paths for cats and dogs """
cat_images = [os.path.join(cat_dir, fname) for fname in cat_names[pic_index-8:pic_index]]
dog_images = [os.path.join(dog_dir, fname) for fname in dog_names[pic_index-8:pic_index]]

""" # Display the images in a grid """
for i, img_path in enumerate(cat_images + dog_images):
    sp = plt.subplot(4, 4, i + 1)
    sp.axis('Off')  # Turn off axis for a clean display

    img = mpimg.imread(img_path)  # Read the image
    plt.imshow(img)  # Show the image

plt.show()  # Display the plot

""" # Preprocessing: Data augmentation and image resizing """
train_datagen = image_dataset_from_directory(base_dir,
                                                  image_size=(200, 200),  # Resize images to 200x200
                                                  subset='training',
                                                  seed=1,
                                                  validation_split=0.1,  # Split dataset into training and validation
                                                  batch_size=32)

test_datagen = image_dataset_from_directory(base_dir,
                                                 image_size=(200, 200),
                                                 subset='validation',
                                                 seed=1,
                                                 validation_split=0.1,
                                                 batch_size=32)

import torch
import torch.nn as nn
import torch.nn.init as init

""" # Define the initializer for weights """
initializer = init.kaiming_uniform_

""" # Define a linear layer and apply the initializer to its weights """
layer = nn.Linear(3, 3)
initializer(layer.weight, a=0, mode='fan_in', nonlinearity='relu')

""" # Custom model definition (simple CNN model) """
class CustomModel(nn.Module):
    def __init__(self):
        super(CustomModel, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3),  # Convolutional layer with 32 filters
            nn.ReLU(),
            nn.MaxPool2d(2),  # Max pooling layer
            nn.Conv2d(32, 64, kernel_size=3),  # Second convolutional layer
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.fc_layers = nn.Sequential(
            nn.Flatten(),  # Flatten the feature map to a vector
            nn.Linear(64 * 48 * 48, 1)  # Fully connected layer
        )

    def forward(self, X):
        X = self.conv_layers(X)
        X = self.fc_layers(X)
        X = torch.sigmoid(X)  # Output activation function
        return X

""" # ResNet10 Model (with residual blocks) """
class ResNet10(nn.Module):
    def __init__(self, num_classes=10, dropout_prob=0.3, init_type="xavier", activation="relu"):
        super(ResNet10, self).__init__()
        
        self.in_channels = 64
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.activation = self._get_activation(activation)
        
        self.layer1 = self._make_layer(64, 2, stride=1, dropout_prob=dropout_prob, activation=activation)
        self.layer2 = self._make_layer(128, 2, stride=2, dropout_prob=dropout_prob, activation=activation)
        self.layer3 = self._make_layer(256, 2, stride=2, dropout_prob=dropout_prob, activation=activation)
        self.layer4 = self._make_layer(512, 2, stride=2, dropout_prob=dropout_prob, activation=activation)

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512, num_classes)

        # Apply weight initialization
        initialize_weights(self, init_type)

    def _get_activation(self, activation):
        if activation == "relu":
            return nn.ReLU(inplace=True)
        elif activation == "tanh":
            return nn.Tanh()
        elif activation == "leaky_relu":
            return nn.LeakyReLU(inplace=True)
        else:
            raise ValueError("Unsupported activation function")

    def _make_layer(self, out_channels, blocks, stride, dropout_prob, activation):
        layers = []
        layers.append(PreActBlock(self.in_channels, out_channels, stride, dropout_prob, activation))
        self.in_channels = out_channels  # Update for next blocks
        
        for _ in range(1, blocks):
            layers.append(PreActBlock(out_channels, out_channels, dropout_prob=dropout_prob, activation=activation))
        
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.activation(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        
        return x

""" # Initialize models """
model2 = ResNet10()

""" # Visualizing model architecture (using torchviz for PyTorch models) """
import torchviz
from torchviz import make_dot

""" # Create a dummy input tensor with appropriate shape (batch_size=1, channels=3, height=200, width=200) """
dummy_input = torch.randn(1, 3, 200, 200)

""" # Generate the visualization for the CustomModel """
output = model(dummy_input)
dot = make_dot(output, params=dict(model.named_parameters()))

""" # Save or render the graph """
dot.render("model_architecture", format="png")  # Saves the visualization as a PNG file
dot.view()  # Opens the visualization in the default viewer

""" # Define loss function and optimizer """
loss_function = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification
optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate of 0.001

""" # Dummy DataLoader setup for training """
X = torch.randn(100, 3, 200, 200) * 255  # 100 images of size 200x200 with 3 channels
y = torch.randint(0, 2, (100, 1)).float()  # 100 binary labels (0 or 1)

X = X / 255.0  # Normalize image data

# Create DataLoader
dataset = TensorDataset(X, y)
train_loader = DataLoader(dataset, batch_size=16, shuffle=True)

""" # Training loop """
num_epochs = 10
for epoch in range(num_epochs):
    model.train()  # Set model to training mode
    total_loss = 0
    correct_predictions = 0
    total_predictions = 0

    """ # Loop through training data """
    for inputs, labels in train_loader:
        optimizer.zero_grad()  # Clear gradients

        outputs = model(inputs)  # Forward pass
        loss = loss_function(outputs, labels)  # Compute loss

        loss.backward()  # Backpropagation
        optimizer.step()  # Update weights

        total_loss += loss.item()

        """ # Convert outputs to binary predictions (threshold at 0.5) """
        predictions = (outputs >= 0.5).float()

        correct_predictions += (predictions == labels).sum().item()
        total_predictions += labels.size(0)

    avg_loss = total_loss / len(train_loader)  # Calculate average loss
    accuracy = correct_predictions / total_predictions * 100  # Calculate accuracy as a percentage

    print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%")

""" # Plotting loss and accuracy """
import matplotlib.pyplot as plt
plt.figure(figsize=(12, 6))

"""# Plot training loss"""
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Loss', color='r')
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

"""# Plot training accuracy"""
plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Accuracy', color='g')
plt.title('Training Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

"""# Display the plots"""
plt.tight_layout()
plt.show()

"""# Evaluate model"""
model.eval()  # Set model to evaluation mode
with torch.no_grad():
    val_accuracy = 0
    for inputs, labels in train_loader:  # Use validation loader if available
        outputs = model(inputs)
        val_accuracy += calculate_accuracy(outputs, labels).item()

    print(f"Validation Accuracy: {val_accuracy / len(train_loader) * 100:.2f}%")

"""# Evaluation for ResNet10 (model2)"""
model2.eval()  # Set model2 to evaluation mode
with torch.no_grad():
    val_accuracy_model2 = 0
    for inputs, labels in train_loader_model2:  # Use validation loader for model2
        outputs = model2(inputs)
        val_accuracy_model2 += calculate_accuracy_model2(outputs, labels).item()
