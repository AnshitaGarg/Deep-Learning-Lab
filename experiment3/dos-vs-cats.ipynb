import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import numpy as np

import warnings
warnings.filterwarnings('ignore')

from tensorflow import keras
from keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.utils import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.preprocessing import image_dataset_from_directory

import os
import matplotlib.image as mpimg 
import kagglehub

# Download latest version of dataset from Kaggle
path = kagglehub.dataset_download("anthonytherrien/dog-vs-cat")

print("Path to dataset files:", path)

# List files in the dataset directory to confirm files have been downloaded
print("Files in dataset directory:", os.listdir(path))

# Define the path to the "animals" directory
animals_path = os.path.join(path, "animals")

# List files inside the "animals" directory to ensure correct dataset structure
print("Files in 'animals' directory:", os.listdir(animals_path))

# Define the base directory for "dog-vs-cat-classification"
base_dir = os.path.join(path, "animals")

# Define paths for "cat" and "dog" directories
cat_dir = os.path.join(base_dir, "cat")
dog_dir = os.path.join(base_dir, "dog")

# List filenames in "cat" and "dog" directories for inspection
cat_names = os.listdir(cat_dir)
dog_names = os.listdir(dog_dir)

# Set up the figure for displaying images in a grid
fig = plt.gcf()
fig.set_size_inches(16, 16)

# Define the index for selecting images
pic_index = 210

# Get a list of image paths for cats and dogs
cat_images = [os.path.join(cat_dir, fname) for fname in cat_names[pic_index-8:pic_index]]
dog_images = [os.path.join(dog_dir, fname) for fname in dog_names[pic_index-8:pic_index]]

# Display the images in a grid
for i, img_path in enumerate(cat_images + dog_images):
    sp = plt.subplot(4, 4, i + 1)
    sp.axis('Off')  # Turn off axis for a clean display

    img = mpimg.imread(img_path)  # Read the image
    plt.imshow(img)  # Show the image

plt.show()  # Display the plot

# Preprocessing: Data augmentation and image resizing
train_datagen = image_dataset_from_directory(base_dir,
                                                  image_size=(200, 200),  # Resize images to 200x200
                                                  subset='training',
                                                  seed=1,
                                                  validation_split=0.1,  # Split dataset into training and validation
                                                  batch_size=32)

test_datagen = image_dataset_from_directory(base_dir,
                                                 image_size=(200, 200),
                                                 subset='validation',
                                                 seed=1,
                                                 validation_split=0.1,
                                                 batch_size=32)

import torch
import torch.nn as nn
import torch.nn.init as init

# Define the initializer for weights
initializer = init.kaiming_uniform_

# Define a linear layer and apply the initializer to its weights
layer = nn.Linear(3, 3)
initializer(layer.weight, a=0, mode='fan_in', nonlinearity='relu')

# Custom model definition (simple CNN model)
class CustomModel(nn.Module):
    def __init__(self):
        super(CustomModel, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3),  # Convolutional layer with 32 filters
            nn.ReLU(),
            nn.MaxPool2d(2),  # Max pooling layer
            nn.Conv2d(32, 64, kernel_size=3),  # Second convolutional layer
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.fc_layers = nn.Sequential(
            nn.Flatten(),  # Flatten the feature map to a vector
